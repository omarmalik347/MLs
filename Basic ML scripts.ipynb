{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y63jvAl0rqSZ"
   },
   "source": [
    "# Train Test Splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2zAEHuTgrznE"
   },
   "source": [
    "Train-test splitting involves dividing a dataset into two parts: one for training a machine learning model (the \"train\" set) and the other for evaluating its performance (the \"test\" set)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5va52byEtJOe"
   },
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "bJ2yTPzMrO-2"
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "khAWfctZtPKm"
   },
   "source": [
    "## 2. Load Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3nLRUuYktQZ1"
   },
   "source": [
    "The iris dataset contains measurements of 150 iris flowers from three different species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ls9gEyOXrsiN"
   },
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "X = iris.data    # Features (e.g., sepal and petal lengths and widths)\n",
    "y = iris.target  # Target labels (species)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pEg7NDmWtpal",
    "outputId": "7fc67763-8a5a-4b24-84c3-6a2cf90308ca"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First 10 values of the iris dataset - input data\n",
    "iris.data[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DYNIxgIXt6I0",
    "outputId": "d9339c15-3ca1-461e-cbd4-587daa51ddbb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# output data\n",
    "iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lILlJpeJtVXH"
   },
   "source": [
    "## 3. Train-Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LUWftPIjtYxu"
   },
   "source": [
    "We'll split the dataset into a training set and a test set using the train_test_split function. The test set will comprise 20% of the total data.\n",
    "\n",
    "python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "oBqQ7NejtTQ_"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mG4boqZeteH0"
   },
   "source": [
    "## 4. Verify the Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FK0-rBKHtg_P"
   },
   "source": [
    "To ensure our data was split correctly, let's print the sizes of our training and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FTTQISjatXJe",
    "outputId": "bcb463f3-7ce3-4370-b2d5-3dc71fa03067"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of Training Set: 120\n",
      "Size of Test Set: 30\n"
     ]
    }
   ],
   "source": [
    "print(f\"Size of Training Set: {len(X_train)}\")\n",
    "print(f\"Size of Test Set: {len(X_test)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Li1iMYaWtluc"
   },
   "source": [
    "# Now, you can use X_train and y_train to train a machine learning model, and then evaluate its performance using X_test and y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0000\n",
      "Confusion Matrix:\n",
      "[[10  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0  0 11]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "\n",
    "logreg = LogisticRegression(max_iter=200) #model selection\n",
    "logreg.fit(X_train, y_train) # training\n",
    "y_pred_logreg = logreg.predict(X_test) #predict\n",
    "\n",
    "# Evaluation\n",
    "accuracy_logreg = accuracy_score(y_test, y_pred_logreg)\n",
    "cm_logreg = confusion_matrix(y_test, y_pred_logreg)\n",
    "\n",
    "print(f\"Accuracy: {accuracy_logreg:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm_logreg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0000\n",
      "Confusion Matrix:\n",
      "[[10  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0  0 11]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=42) #model selection\n",
    "dt.fit(X_train, y_train) #training\n",
    "y_pred_dt = dt.predict(X_test) #prediction\n",
    "\n",
    "# Evaluation\n",
    "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
    "cm_dt = confusion_matrix(y_test, y_pred_dt)\n",
    "\n",
    "print(f\"Accuracy: {accuracy_dt:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm_dt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0000\n",
      "Confusion Matrix:\n",
      "[[10  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0  0 11]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42) #model selection\n",
    "rf.fit(X_train, y_train) #training\n",
    "y_pred_rf = rf.predict(X_test) #prediction\n",
    "\n",
    "# Evaluation\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "cm_rf = confusion_matrix(y_test, y_pred_rf)\n",
    "\n",
    "print(f\"Accuracy: {accuracy_rf:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm_rf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. K-Nearest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0000\n",
      "Confusion Matrix:\n",
      "[[10  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0  0 11]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "knn = KNeighborsClassifier() #model selection\n",
    "knn.fit(X_train, y_train) #training\n",
    "y_pred_knn = knn.predict(X_test) #prediction\n",
    "\n",
    "# Evaluation\n",
    "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
    "cm_knn = confusion_matrix(y_test, y_pred_knn)\n",
    "\n",
    "print(f\"Accuracy: {accuracy_knn:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm_knn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0000\n",
      "Confusion Matrix:\n",
      "[[10  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0  0 11]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "nb = GaussianNB() #model selection\n",
    "nb.fit(X_train, y_train) #training\n",
    "y_pred_nb = nb.predict(X_test) #prediction\n",
    "\n",
    "# Evaluation\n",
    "accuracy_nb = accuracy_score(y_test, y_pred_nb)\n",
    "cm_nb = confusion_matrix(y_test, y_pred_nb)\n",
    "\n",
    "print(f\"Accuracy: {accuracy_nb:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm_nb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. SVM - support vector machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0000\n",
      "Confusion Matrix:\n",
      "[[10  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0  0 11]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "svm = SVC(random_state=42) #model selection\n",
    "svm.fit(X_train, y_train) #training\n",
    "y_pred_svm = svm.predict(X_test) #prediction\n",
    "\n",
    "# Evaluation\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "cm_svm = confusion_matrix(y_test, y_pred_svm)\n",
    "\n",
    "print(f\"Accuracy: {accuracy_svm:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm_svm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0000\n",
      "Confusion Matrix:\n",
      "[[10  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0  0 11]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "mlp = MLPClassifier(max_iter=1000, random_state=42) #model selection\n",
    "mlp.fit(X_train, y_train) #training\n",
    "y_pred_mlp = mlp.predict(X_test) #prediction\n",
    "\n",
    "# Evaluation\n",
    "accuracy_mlp = accuracy_score(y_test, y_pred_mlp)\n",
    "cm_mlp = confusion_matrix(y_test, y_pred_mlp)\n",
    "\n",
    "print(f\"Accuracy: {accuracy_mlp:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm_mlp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0000\n",
      "Confusion Matrix:\n",
      "[[10  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0  0 11]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "gb = GradientBoostingClassifier(random_state=42) #model selection\n",
    "gb.fit(X_train, y_train) #training\n",
    "y_pred_gb = gb.predict(X_test) #prediction\n",
    "\n",
    "# Evaluation\n",
    "accuracy_gb = accuracy_score(y_test, y_pred_gb)\n",
    "cm_gb = confusion_matrix(y_test, y_pred_gb)\n",
    "\n",
    "\n",
    "print(f\"Accuracy: {accuracy_gb:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm_gb)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
